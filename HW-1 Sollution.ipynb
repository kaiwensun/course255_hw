{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============ 5 most frequent 1-grams\n",
      "\n",
      "index\tcount\tngram\n",
      "1.\t14620: \t\"the\"\n",
      "2.\t6732: \t\"of\"\n",
      "3.\t6502: \t\"and\"\n",
      "4.\t4799: \t\"a\"\n",
      "5.\t4706: \t\"to\"\n",
      "\n",
      "============ 5 most frequent 2-grams\n",
      "\n",
      "index\tcount\tngram\n",
      "1.\t1906: \t\"of the\"\n",
      "2.\t1193: \t\"in the\"\n",
      "3.\t746: \t\"to the\"\n",
      "4.\t444: \t\"from the\"\n",
      "5.\t413: \t\"the whale\"\n",
      "\n",
      "============ 5 most frequent 3-grams\n",
      "\n",
      "index\tcount\tngram\n",
      "1.\t116: \t\"the sperm whale\"\n",
      "2.\t109: \t\"of the whale\"\n",
      "3.\t88: \t\"the white whale\"\n",
      "4.\t64: \t\"one of the\"\n",
      "5.\t60: \t\"of the sea\"\n",
      "\n",
      "============ 5 most frequent 4-grams\n",
      "\n",
      "index\tcount\tngram\n",
      "1.\t43: \t\"of the sperm whale\"\n",
      "2.\t27: \t\"the sperm whale s\"\n",
      "3.\t20: \t\"at the same time\"\n",
      "4.\t18: \t\"project gutenberg tm electronic\"\n",
      "5.\t18: \t\"of the whale s\"\n",
      "\n",
      "============ 5 most frequent 5-grams\n",
      "\n",
      "index\tcount\tngram\n",
      "1.\t13: \t\"the project gutenberg literary archive\"\n",
      "2.\t13: \t\"project gutenberg literary archive foundation\"\n",
      "3.\t12: \t\"project gutenberg tm electronic works\"\n",
      "4.\t11: \t\"of the sperm whale s\"\n",
      "5.\t10: \t\"and at the same time\"\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def string2ngrams(n,string):\n",
    "    #lst = re.split(\"[\\s]\",string)\n",
    "    lst = re.split(\"[^0-9a-z]\",string)\n",
    "    ngrams = zip(*[lst[i:] for i in xrange(n)])\n",
    "    return ngrams\n",
    "\n",
    "def countNGrams(n,sentences):\n",
    "    ngrams = sentences.map(lambda string:string2ngrams(n,string))\n",
    "    counter = ngrams.flatMap(lambda ngram:(\" \".join(ngram),1)).reduceByKey(lambda a,b:a+b)\n",
    "    return counter\n",
    "\n",
    "def preprocessFile2Sentences(filename):\n",
    "    textRDD = sc.newAPIHadoopFile(filename,\n",
    "                              'org.apache.hadoop.mapreduce.lib.input.TextInputFormat',\n",
    "                              'org.apache.hadoop.io.LongWritable',\n",
    "                              'org.apache.hadoop.io.Text',\n",
    "                               conf={'textinputformat.record.delimiter': \"\\r\\n\\r\\n\"}) \\\n",
    "            .map(lambda x: x[1])\n",
    "\n",
    "    sentences=textRDD.flatMap(lambda x: x.split(\". \"))\n",
    "    sentences=sentences.map(lambda sent:\" \".join(re.findall('\\w+',sent.lower())))\n",
    "    return sentences\n",
    "\n",
    "def get_Freq_ngramRDD(n, sentences):\n",
    "    ngrams = sentences.map(lambda string:string2ngrams(n,string))\n",
    "    collection_of_ngrams = ngrams.flatMap(lambda x:(map(lambda y:(y,1),x)))\n",
    "    sorted_counter = collection_of_ngrams.reduceByKey(lambda a,b:a+b).map(lambda (x,y):(y,x)).sortBy(lambda x:x[0] ,False)\n",
    "    return sorted_counter\n",
    "\n",
    "def printOutput(n,freq_ngramRDD):\n",
    "    top=freq_ngramRDD.take(5)\n",
    "    print '\\n============ %d most frequent %d-grams'%(5,n)\n",
    "    print '\\nindex\\tcount\\tngram'\n",
    "    for i in range(5):\n",
    "        #print top[i][1]\n",
    "        print '%d.\\t%d: \\t\"%s\"'%(i+1,top[i][0],' '.join(top[i][1]))\n",
    "\n",
    "\n",
    "#filename = '../Data/mydic.txt'\n",
    "filename = '../Data/Moby-Dick.txt'\n",
    "sentences = preprocessFile2Sentences(filename)\n",
    "#so far, each element of sentences is a well preprocessed sentence\n",
    "\n",
    "for n in range(1,6):\n",
    "#    Put your logic for generating the sorted n-gram RDD here and store it in freq_ngramRDD variable\n",
    "    freq_ngramRDD = get_Freq_ngramRDD(n,sentences)\n",
    "    printOutput(n,freq_ngramRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
